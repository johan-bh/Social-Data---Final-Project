{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbh\\AppData\\Local\\Temp\\ipykernel_6972\\3090426702.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Load the cleaned data file\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "# parent_dir = os.path.dirname(cwd)\n",
    "# print(parent_dir)\n",
    "filename = r'C:\\Users\\jbh\\Desktop\\NYPD_Complaint_Data_Cleaned.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sex</th>\n",
       "      <th>crime_id</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>40.733512</td>\n",
       "      <td>-74.003532</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>40.838194</td>\n",
       "      <td>-73.912268</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>40.872153</td>\n",
       "      <td>-73.866141</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>40.681003</td>\n",
       "      <td>-73.990213</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>40.801754</td>\n",
       "      <td>-73.931203</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170547</th>\n",
       "      <td>40.738164</td>\n",
       "      <td>-73.860752</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170551</th>\n",
       "      <td>40.739659</td>\n",
       "      <td>-73.774110</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170552</th>\n",
       "      <td>40.685418</td>\n",
       "      <td>-73.730032</td>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170553</th>\n",
       "      <td>40.598482</td>\n",
       "      <td>-73.757091</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8170554</th>\n",
       "      <td>40.661875</td>\n",
       "      <td>-73.738171</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995047 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               lat        lon sex  crime_id  day  year  hour\n",
       "62       40.733512 -74.003532   F         0    0  2020    19\n",
       "63       40.838194 -73.912268   M         1    0  2020    14\n",
       "64       40.872153 -73.866141   F         2    1  2020    19\n",
       "65       40.681003 -73.990213   F         0    2  2021     8\n",
       "66       40.801754 -73.931203   M         1    3  2021     5\n",
       "...            ...        ...  ..       ...  ...   ...   ...\n",
       "8170547  40.738164 -73.860752   F         0    2  2022     5\n",
       "8170551  40.739659 -73.774110   M         0    2  2022    14\n",
       "8170552  40.685418 -73.730032   M         6    4  2020     0\n",
       "8170553  40.598482 -73.757091   F         0    5  2022    15\n",
       "8170554  40.661875 -73.738171   F         6    1  2022     8\n",
       "\n",
       "[995047 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Focus crimes: FELONY ASSAULT, ROBBERY, RAPE\n",
    "focus_crimes = [\n",
    "    'HARRASSMENT 2', \n",
    "    'ROBBERY', \n",
    "    'ASSAULT 3 & RELATED OFFENSES', \n",
    "    'FELONY ASSAULT', \n",
    "    'PETIT LARCENY', \n",
    "    'GRAND LARCENY',\n",
    "    'SEX CRIMES',\n",
    "    'RAPE'\n",
    "]\n",
    "\n",
    "\n",
    "df_focus = df[df['Offense_Description'].isin(focus_crimes)]\n",
    "\n",
    "\n",
    "# Keep columns: Complaint_From_Date, Complaint_From_Time, Lattitude, Longtitude, Victim_Sex\n",
    "df_focus = df_focus[['Complaint_From_Date', 'Complaint_From_Time', 'Latitude', 'Longitude', 'Victim_Sex', 'Offense_Description']]\n",
    "\n",
    "# Drop rows where Victim_Sex is not \"M\" or \"F\" (D=Business/Organization and E = PSNY/People of the State of New York which is not relevant to the case)\n",
    "df_focus = df_focus[df_focus['Victim_Sex'] != 'D']\n",
    "df_focus = df_focus[df_focus['Victim_Sex'] != 'E']\n",
    "# The footnotes doesn't provide any useful information on the Victim_Sex == \"L\". We think it might be \"Lady\" or \"LQBTQ\" but we are not sure. So we will drop these rows. \n",
    "# In this subset of data, they only account for approx 800 rows out of 800k rows. So it's not a big deal to drop them.\n",
    "df_focus = df_focus[df_focus['Victim_Sex'] != 'L']\n",
    "\n",
    "\n",
    "# convert to datetime\n",
    "df_focus['Complaint_From_Date'] = pd.to_datetime(df_focus['Complaint_From_Date'])\n",
    "# create a column \"DayOfWeek\" and remove the column \"Complaint_From_Date\"\n",
    "df_focus['weekday'] = df_focus['Complaint_From_Date'].dt.day_name()\n",
    "\n",
    "# create a column \"year\" with the year of the date\n",
    "df_focus['year'] = df_focus['Complaint_From_Date'].dt.year\n",
    "\n",
    "df_focus = df_focus[df_focus['year'] >= 2019]\n",
    "\n",
    "df_focus = df_focus.drop(columns=['Complaint_From_Date'])\n",
    "\n",
    "# convert Complaint_From_Time to datetime\n",
    "df_focus['Complaint_From_Time'] = pd.to_datetime(df_focus['Complaint_From_Time'], format='%H:%M:%S').dt.time\n",
    "# create a column \"hour\" and remove the column \"Complaint_From_Time\"\n",
    "df_focus['hour'] = pd.to_datetime(df_focus['Complaint_From_Time'], format='%H:%M:%S').dt.hour\n",
    "df_focus = df_focus.drop(columns=['Complaint_From_Time'])\n",
    "\n",
    "# loop through all unique Offense_Descriptions and assign it an arbitrary number\n",
    "offense_description_dict = {}\n",
    "for i, offense_description in enumerate(df_focus['Offense_Description'].unique()):\n",
    "    offense_description_dict[offense_description] = i\n",
    "\n",
    "# save the dictionary to a json file\n",
    "with open('offense_description_dict_usecase1.json', 'w') as f:\n",
    "    json.dump(offense_description_dict, f)\n",
    "\n",
    "# map the Offense_Description to the arbitrary number\n",
    "df_focus['Offense_Description'] = df_focus['Offense_Description'].map(offense_description_dict)\n",
    "\n",
    "# rename Offense_Description to \"crime_id\"\n",
    "df_focus = df_focus.rename(columns={'Offense_Description': 'crime_id'})\n",
    "\n",
    "# loop through weekday and assign number from 0 to 6\n",
    "weekday_dict = {}\n",
    "for i, weekday in enumerate(df_focus['weekday'].unique()):\n",
    "    weekday_dict[weekday] = i\n",
    "\n",
    "# map the weekday to the arbitrary number\n",
    "df_focus['weekday'] = df_focus['weekday'].map(weekday_dict)\n",
    "\n",
    "# rename weekday to \"day\"\n",
    "df_focus = df_focus.rename(columns={'weekday': 'day'})\n",
    "\n",
    "# rename Victim_Sex to \"sex\"\n",
    "df_focus = df_focus.rename(columns={'Victim_Sex': 'sex'})\n",
    "\n",
    "# convert latitude and longitude to float\n",
    "df_focus['Latitude'] = df_focus['Latitude'].astype(float)\n",
    "df_focus['Longitude'] = df_focus['Longitude'].astype(float)\n",
    "\n",
    "# rename to \"lat\" and \"lon\"\n",
    "df_focus = df_focus.rename(columns={'Latitude': 'lat', 'Longitude': 'lon'})\n",
    "\n",
    "# only keep 10k rows for now\n",
    "# df_focus = df_focus.sample(n=10000)\n",
    "\n",
    "# save the df to json with comma separated entries encapulated in square brackets\n",
    "df_focus.to_json('DataUseCase1-v2.json', orient='records', lines=False)\n",
    "\n",
    "df_focus\n",
    "\n",
    "# REMEMBER TO UPDATE THE HTML FOR USECASE1 WITH CHANGES MADE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Website URL to scrape precinct addresses\n",
    "url = \"https://www.nyc.gov/site/nypd/bureaus/patrol/precincts-landing.page\"\n",
    "\n",
    "# Make an HTTP request to the server\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# find the table with the \"Address\" of the precincts\n",
    "table = soup.find_all('table')[0]\n",
    "\n",
    "# Get thet td's with data-label=\"Address\"\n",
    "tds = table.find_all('td', {'data-label': 'Address'})\n",
    "\n",
    "# only keep the text of the td's and apend \", New Yowk, NY\" to the end\n",
    "addresses = [td.text + \", New York, NY\" for td in tds]\n",
    "\n",
    "# Initialize Nominatim API\n",
    "geolocator = Nominatim(user_agent=\"nypd_crime_data\")\n",
    "\n",
    "# Using rate limiter to avoid overloading the API server\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "\n",
    "# Dictionary to hold addresses and their coordinates\n",
    "location_dict = {}\n",
    "\n",
    "for address in addresses:\n",
    "    location = geocode(address)\n",
    "    if location:\n",
    "        location_dict[address] = [location.latitude, location.longitude]\n",
    "        print(f\"Coordinates for {address}: {location.latitude}, {location.longitude}\")\n",
    "    else:\n",
    "        location_dict[address] = None\n",
    "        print(f\"Could not find coordinates for {address}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16 Ericsson Place, New York, NY': [40.7204814, -74.0071343], '19 Elizabeth Street, New York, NY': [40.7161816, -73.9974633], '233 West 10 Street, New York, NY': (40.73397, -74.00543), '19 1/2 Pitt Street, New York, NY': [40.7162871, -73.9837703], '321 East 5 Street, New York, NY': [40.68395150938213, -74.00023343224551], '230 West 20th Street, New York, NY': [40.74292291676375, -73.99856790155677], '230 East 21st Street, New York, NY': [40.6487106, -73.9598669], '357 West 35th Street, New York, NY': [40.7538182, -73.9949851], '167 East 51st Street, New York, NY': [40.7567621, -73.9707859], '306 West 54th Street, New York, NY': [40.76496015, -73.9850868531467], '153 East 67th Street, New York, NY': [40.767145549999995, -73.96381319536516], '120 West 82nd Street, New York, NY': [40.7840868, -73.97508305171637], '86th St & Transverse Road, New York, NY': [40.7850215, -73.9685893], '164 East 102nd Street, New York, NY': [40.7891815, -73.9472169], '151 West 100th Street, New York, NY': [40.7964779, -73.967428], '120 East 119th Street, New York, NY': [40.80069235, -73.94111874373155], '520 West 126th Street, New York, NY': [40.81469, -73.95653594153396], '2271-89 8th Avenue, New York, NY': (40.81937, -73.944458), '451 West 151st Street, New York, NY': [40.8288745, -73.94377772909826], '250 West 135th Street, New York, NY': [40.8157476, -73.9453969], '2207 Amsterdam Avenue, New York, NY': [40.8405867, -73.93573663316083], '4295 Broadway, New York, NY': [40.851527149999995, -73.93537316409075], '257 Alexander Avenue, New York, NY': [40.8103299, -73.925216], '1035 Longwood Avenue, New York, NY': [40.8163385, -73.89567449823033], '830 Washington Avenue, New York, NY': [40.8224638, -73.91123310877224], '900 Fteley Avenue, New York, NY': [40.82307095, -73.86974050594586], '2 East 169th Street, New York, NY': [40.83730475, -73.92002852824726], '2877 Barkley Avenue, New York, NY': [40.8307425, -73.8272355], '2120 Ryer Avenue, New York, NY': [40.8540411, -73.9001068], '4111 Laconia Avenue, New York, NY': [40.88751135, -73.84755406628824], '450 Cross Bronx Expressway, New York, NY': [40.84420124489796, -73.89798069387756], '2121 Eastchester Road, New York, NY': [40.8560926, -73.84438278180977], '3450 Kingsbridge Avenue, New York, NY': [40.8834823, -73.90241725394398], '3016 Webster Avenue, New York, NY': [40.8690538, -73.87965546376213], '2951 West 8th Street, New York, NY': [40.57651505, -73.97609753793938], '2575 Coney Island Avenue, New York, NY': [40.594171349999996, -73.96048726556828], '1925 Bath Avenue, New York, NY': [40.6025772, -74.00299988095668], '1844 Brooklyn Avenue, New York, NY': [40.6279617, -73.94160667402886], '5822 16th Avenue, New York, NY': [40.6257785, -73.99135492860181], '2820 Snyder Avenue, New York, NY': [40.6487689, -73.95019], '333 65th Street, New York, NY': [40.6389413, -74.0226488], '9720 Foster Avenue, New York, NY': [40.648490499999994, -73.90496134444203], '154 Lawrence Avenue, New York, NY': [40.63035295, -73.97372085139176], '421 Empire Boulevard, New York, NY': [40.6645423, -73.94788400186542], '830 4th Avenue, New York, NY': [40.65818805, -74.0010755573444], '1470 East New York Avenue, New York, NY': [40.67078385, -73.91354331061422], '1000 Sutter Avenue, New York, NY': [40.67117035, -73.88145873279599], '191 Union Street, New York, NY': [40.68398405280686, -74.00021197457406], '127 Utica Avenue, New York, NY': [40.67477385, -73.93024528334647], '65 6th Avenue, New York, NY': [40.68098252930562, -73.97432521099944], '263 Tompkins Avenue, New York, NY': [40.6888386, -73.94470605912969], '30 Ralph Avenue, New York, NY': [40.6897012, -73.9242145], '480 Knickerbocker Avenue, New York, NY': [40.6981536, -73.91787129404761], '301 Gold Street, New York, NY': [40.6955512, -73.983071], '298 Classon Avenue, New York, NY': [40.69008425, -73.96048450772389], '211 Union Avenue, New York, NY': [40.7064437669646, -73.95075847457295], '100 Meserole Avenue, New York, NY': [40.726806, -73.953204], '92-24 Rockaway Beach Boulevard, New York, NY': [40.5862476, -73.8164846], '16-12 Mott Avenue, New York, NY': [40.6029503, -73.7499972], '87-34 118th Street, New York, NY': [40.6986152, -73.8312172], '168-02 P.O Edward Byrne Ave., New York, NY': (40.70699, -73.79256), '64-2 Catalpa Avenue, New York, NY': [40.7007889, -73.9041025], '92-08 222nd Street, New York, NY': [40.72617005, -73.73512860655313], '103-53 101st Street, New York, NY': [40.68219860000001, -73.83974945], '71-01 Parsons Boulevard, New York, NY': [40.7299492, -73.81062673923094], '5-47 50th Avenue, New York, NY': [40.74303995, -73.95474394328949], '37-05 Union Street, New York, NY': [40.762352199999995, -73.82702044854032], '94-41 43rd Avenue, New York, NY': [40.745239, -73.869946], '45-06 215th Street, New York, NY': [40.76021895, -73.76774854628971], '68-40 Austin Street, New York, NY': [40.722245900000004, -73.85111500966215], '167-02 Baisley Boulevard, New York, NY': [40.6799224, -73.7758415], '34-16 Astoria Boulevard, New York, NY': [40.76927625, -73.91535420061777], '92-15 Northern Boulevard, New York, NY': [40.756843599999996, -73.8755332327489], '78 Richmond Terrace, New York, NY': [40.64464375, -74.07741756960358], '970 Richmond Avenue, New York, NY': [40.62360285, -74.15017176910112], '2320 Hylan Boulevard, New York, NY': [40.57413235, -74.10549505277004], '116 Main Street, New York, NY': (40.51198223739609, -74.25005736108977)}\n"
     ]
    }
   ],
   "source": [
    "# print addressses that are None\n",
    "for address, location in location_dict.items():\n",
    "    if location is None:\n",
    "        print(address)\n",
    "\n",
    "# manually add the missing coordinates\n",
    "missing_addresses = [(40.733970, -74.005430), (40.819370, -73.944458), (40.706990, -73.792560),(40.51198223739609, -74.25005736108977)]\n",
    "\n",
    "# add the missing coordinates to the location_dict\n",
    "for i, address in enumerate(location_dict.keys()):\n",
    "    if location_dict[address] is None:\n",
    "        location_dict[address] = missing_addresses.pop(0)\n",
    "\n",
    "# check if there are any missing coordinates\n",
    "for address, location in location_dict.items():\n",
    "    if location is None:\n",
    "        print(address)\n",
    "\n",
    "print(location_dict)\n",
    "\n",
    "# errors caught by viewing the markers on the map, appending the New York, NY to the address is not best practice\n",
    "location_dict[\"230 West 20th Street, New York, NY\"] = [40.74292291676375, -73.99856790155677]\n",
    "location_dict[\"191 Union Street, New York, NY\"] = [40.68398405280686, -74.00021197457406]\n",
    "location_dict[\"321 East 5 Street, New York, NY\"] = [40.68395150938213, -74.00023343224551]\n",
    "location_dict[\"211 Union Avenue, New York, NY\"] = [40.7064437669646, -73.95075847457295]\n",
    "location_dict[\"65 6th Avenue, New York, NY\"] = [40.68098252930562, -73.97432521099944]\n",
    "\n",
    "\n",
    "# save the location_dict to json\n",
    "with open('webpage_data/precinct_locations.json', 'w') as fp:\n",
    "    json.dump(location_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offense_Description\n",
      "PETIT LARCENY                     0.530108\n",
      "CRIMINAL MISCHIEF & RELATED OF    0.155869\n",
      "GRAND LARCENY                     0.096712\n",
      "BURGLARY                          0.085070\n",
      "ROBBERY                           0.027026\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # focus crimes use case 2\n",
    "# # busines owner wants to avoid all crimes towards businesses, i.e. Victim_Sex == \"D\"\n",
    "df_focus2 = df\n",
    "\n",
    "# Keep columns: Complaint_From_Date, Complaint_From_Time, Lattitude, Longtitude, Victim_Sex\n",
    "df_focus2 = df_focus2[['Complaint_From_Date', 'Latitude', 'Longitude', 'Victim_Sex', 'Offense_Description']]\n",
    "\n",
    "# keep rows where Victim_Sex is \"D\" (Business/Organization)\n",
    "df_focus2 = df_focus2[df_focus2['Victim_Sex'] == 'D']\n",
    "\n",
    "# drop Victim_Sex\n",
    "df_focus2 = df_focus2.drop(columns=['Victim_Sex'])\n",
    "\n",
    "# convert to datetime\n",
    "df_focus2['Complaint_From_Date'] = pd.to_datetime(df_focus2['Complaint_From_Date'])\n",
    "# create a column \"Year\" and remove the column \"Complaint_From_Date\"\n",
    "df_focus2['Year'] = df_focus2['Complaint_From_Date'].dt.year\n",
    "df_focus2 = df_focus2.drop(columns=['Complaint_From_Date'])\n",
    "\n",
    "# set latitude and longitude to float\n",
    "df_focus2['Latitude'] = df_focus2['Latitude'].astype(float)\n",
    "df_focus2['Longitude'] = df_focus2['Longitude'].astype(float)\n",
    "\n",
    "# rename to \"lat\" and \"lon\"\n",
    "df_focus2 = df_focus2.rename(columns={'Latitude': 'lat', 'Longitude': 'lon'})\n",
    "\n",
    "# the top 5 most prevalent Offense_Descriptions (normalize value counts)\n",
    "value_counts = df_focus2['Offense_Description'].value_counts(normalize=True)\n",
    "print(value_counts.head())\n",
    "\n",
    "# rename \"Offense_Description\" to \"crime_id\"\n",
    "df_focus2 = df_focus2.rename(columns={'Offense_Description': 'crime_id'})\n",
    "\n",
    "# only keep the entries where the normalize crime value_count is above 0.01\n",
    "value_counts = df_focus2['crime_id'].value_counts(normalize=True)\n",
    "# print(value_counts)\n",
    "to_keep = value_counts[value_counts > 0.01].index\n",
    "df_focus2 = df_focus2[df_focus2['crime_id'].isin(to_keep)]\n",
    "\n",
    "# loop through all unique Offense_Descriptions and assign it an arbitrary number\n",
    "offense_description_dict = {}\n",
    "for i, offense in enumerate(df_focus2['crime_id'].unique()):\n",
    "    offense_description_dict[offense] = i\n",
    "    \n",
    "df_focus2['crime_id'] = df_focus2['crime_id'].map(offense_description_dict)\n",
    "\n",
    "# save the offense_description_dict to json\n",
    "with open('offense_description_dict.json', 'w') as fp:\n",
    "    json.dump(offense_description_dict, fp)\n",
    "\n",
    "\n",
    "# only use the years 2019 to 2022\n",
    "df_focus2 = df_focus2[df_focus2['Year'] >= 2019]\n",
    "df_focus2.shape\n",
    "\n",
    "# save the df to json with comma separated entries encapulated in square brackets\n",
    "df_focus2.to_json('DataUseCase2-v2.json', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import warnings\n",
    "# suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load the data\n",
    "file_path = \"C:\\\\Users\\\\jbh\\\\Desktop\\\\SocialData_FinalProject\\\\nyc_decennialcensusdata_2010_2020_change-core-geographies.xlsx\"\n",
    "data_2020 = pd.read_excel(file_path, sheet_name='2020', nrows=6)\n",
    "\n",
    "# Set the index and drop unnecessary rows\n",
    "data_2020.set_index('Borough', inplace=True)\n",
    "data_2020 = data_2020.drop('New York City', axis=0)\n",
    "\n",
    "# Define columns to keep\n",
    "columns_to_keep = ['Pop1', 'Male P', 'MdAge', 'PopU18P', 'Pop65plP', 'PopAcre', 'Hsp1P', 'WNHP', 'BNHP', 'ANHP', 'ONHP', 'TwoPlNHP', 'HmOwnVcRt', 'RntVcRt', 'AvgHHSz']\n",
    "data_2020 = data_2020[columns_to_keep]\n",
    "\n",
    "cmap = sns.color_palette(\"viridis\", n_colors=5, as_cmap=True)\n",
    "\n",
    "# Normalize data in each column\n",
    "normalized_data = (data_2020 - data_2020.min()) / (data_2020.max() - data_2020.min())\n",
    "\n",
    "# Map normalized values to colors\n",
    "color_data = normalized_data.applymap(lambda x: cmap(x))\n",
    "\n",
    "# Convert color data to hex format\n",
    "hex_color_data = color_data.applymap(lambda x: mcolors.to_hex(x))\n",
    "\n",
    "# Combine the original data with the hex color data\n",
    "combined_data = pd.concat([data_2020, hex_color_data], keys=['Values', 'Colors'], axis=1)\n",
    "\n",
    "# This function generates the structured dictionary as you described\n",
    "def generate_data_dict(data, color_data):\n",
    "    # This dictionary will hold the final structured data\n",
    "    structured_dict = {}\n",
    "    \n",
    "    # Iterate over each column in the original data\n",
    "    for col in data.columns:\n",
    "        # List to hold the data for the current column\n",
    "        column_data_list = []\n",
    "        \n",
    "        # Iterate over each borough in the DataFrame\n",
    "        for borough in data.index:\n",
    "            # Create a dictionary for each borough\n",
    "            borough_dict = {\n",
    "                'borough': borough,\n",
    "                'value': data.loc[borough, col],\n",
    "                'color': color_data.loc[borough, col]\n",
    "            }\n",
    "            # Append the borough dictionary to the list for the current column\n",
    "            column_data_list.append(borough_dict)\n",
    "        \n",
    "        # Add the list to the structured dictionary under the column name\n",
    "        structured_dict[col] = column_data_list\n",
    "    \n",
    "    return structured_dict\n",
    "\n",
    "# Call the function to generate the dictionary\n",
    "final_data_dict = generate_data_dict(data_2020, hex_color_data)\n",
    "\n",
    "# Now 'final_data_dict' contains your data in the required structure\n",
    "print(final_data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
